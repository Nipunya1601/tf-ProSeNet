{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Layer as KerasLayer\n",
    "from tensorflow.keras.layers import InputLayer, GRU, LSTM, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prototype(KerasLayer):\n",
    "    def __init__(self, k, **kwargs):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        k : int\n",
    "            Number of prototype vectors to create.\n",
    "        \"\"\"\n",
    "        super(Prototype, self).__init__(**kwargs)\n",
    "        self.k = k\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        print(f'Called `build` with input_shape: {input_shape}')\n",
    "\n",
    "        # what initializer should we use?\n",
    "        self.prototypes = self.add_weight(\n",
    "            name='prototypes',\n",
    "            shape=(1, self.k, input_shape[-1]),\n",
    "            initializer='random_normal',\n",
    "            trainable=True\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        # add reg losses here?\n",
    "\n",
    "        # L2 distances from prototypes\n",
    "        x = tf.expand_dims(x, -2)\n",
    "        d2 = tf.norm(x - self.prototypes, ord=2, axis=-1)\n",
    "\n",
    "        # return exponentially squashed\n",
    "        return tf.exp(-d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn(input_shape=(None, 6),\n",
    "        layer_type='lstm',\n",
    "        layer_args={},\n",
    "        layers=[32,64],\n",
    "        dropout_rate=None):\n",
    "    \"\"\"\n",
    "    Recurrent NN Encoder constructor function.\n",
    "    One layer of `layer_type` will be created for each int in `layers`.\n",
    "    All except the final recurrent layer will return sequences.\n",
    "    \"\"\"\n",
    "    num_layers = len(layers)\n",
    "    assert num_layers > 0, 'Must have at least one layer'\n",
    "\n",
    "    layer_fn = GRU if 'gru' in layer_type.lower() else LSTM\n",
    "\n",
    "    # Construct model\n",
    "    model = Sequential([InputLayer(input_shape=input_shape)])\n",
    "\n",
    "    for i, layer_units in enumerate(layers):\n",
    "        return_seq = False if (i == (num_layers - 1)) else True\n",
    "\n",
    "        next_layer = layer_fn(layer_units, return_sequences=return_seq, name=layer_type+str(i), **layer_args)\n",
    "\n",
    "        model.add(Bidirectional(next_layer))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((None, None, 6), (None, 128))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_model = rnn()\n",
    "enc_model.input_shape, enc_model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Called `build` with input_shape: (None, 128)\n",
      "`x` is now: Tensor(\"prototype/ExpandDims:0\", shape=(None, 1, 128), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((None, None, 6), (None, 16))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_model.add(Prototype(16))\n",
    "enc_model.input_shape, enc_model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional (Bidirectional (None, None, 64)          9984      \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128)               66048     \n",
      "_________________________________________________________________\n",
      "prototype (Prototype)        (None, 16)                2048      \n",
      "=================================================================\n",
      "Total params: 78,080\n",
      "Trainable params: 78,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "enc_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.convert_to_tensor(np.random.rand(10,8,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer bidirectional is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "`x` is now: [[[-0.00283582  0.01728691 -0.0740431  ...  0.07896393 -0.02567625\n",
      "   -0.06429633]]\n",
      "\n",
      " [[ 0.00809463  0.03288684 -0.07838279 ...  0.05920749 -0.02930295\n",
      "   -0.05421176]]\n",
      "\n",
      " [[-0.03309038  0.02737395 -0.0384291  ...  0.07808799 -0.00481567\n",
      "   -0.07680376]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.0286273   0.03764081 -0.04810949 ...  0.06464016  0.00786803\n",
      "   -0.07525987]]\n",
      "\n",
      " [[-0.03038388  0.02889684 -0.05141699 ...  0.06042515 -0.00281157\n",
      "   -0.06354368]]\n",
      "\n",
      " [[-0.01513464  0.01721616 -0.06005955 ...  0.08614102 -0.02160347\n",
      "   -0.07351992]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=3312, shape=(10, 16), dtype=float32, numpy=\n",
       "array([[0.47671127, 0.47191462, 0.45663172, 0.48426074, 0.4807453 ,\n",
       "        0.4670902 , 0.48034397, 0.45819017, 0.47455812, 0.4826773 ,\n",
       "        0.5079952 , 0.47092006, 0.46108443, 0.43865827, 0.428171  ,\n",
       "        0.4758821 ],\n",
       "       [0.49069038, 0.4959423 , 0.47992632, 0.50275016, 0.49121913,\n",
       "        0.48237574, 0.49310982, 0.47888592, 0.4844642 , 0.49402687,\n",
       "        0.51913023, 0.48373684, 0.48320827, 0.45336345, 0.44548222,\n",
       "        0.4957009 ],\n",
       "       [0.47904727, 0.47409672, 0.46658087, 0.49456388, 0.48433197,\n",
       "        0.46448818, 0.50406414, 0.45822912, 0.485006  , 0.4970835 ,\n",
       "        0.5234908 , 0.4791789 , 0.47352928, 0.4408275 , 0.43995106,\n",
       "        0.48136073],\n",
       "       [0.48616424, 0.49252707, 0.4771477 , 0.50048476, 0.48837665,\n",
       "        0.47548854, 0.5087809 , 0.47938898, 0.47887725, 0.49530175,\n",
       "        0.5285961 , 0.48416895, 0.48002526, 0.44420543, 0.4444706 ,\n",
       "        0.49788713],\n",
       "       [0.49068144, 0.49738473, 0.4816463 , 0.5012724 , 0.49493203,\n",
       "        0.4836188 , 0.5012713 , 0.47985038, 0.49542907, 0.49740076,\n",
       "        0.5218812 , 0.48684007, 0.4839253 , 0.45497736, 0.44733363,\n",
       "        0.50103056],\n",
       "       [0.48064572, 0.47736707, 0.46321478, 0.48929447, 0.48958024,\n",
       "        0.46743426, 0.4953369 , 0.46125108, 0.47724435, 0.48835018,\n",
       "        0.5167813 , 0.4785748 , 0.47091833, 0.44356528, 0.43582296,\n",
       "        0.4849571 ],\n",
       "       [0.4758481 , 0.47964853, 0.4654415 , 0.48369318, 0.4848772 ,\n",
       "        0.46856448, 0.49299148, 0.45949334, 0.48702225, 0.4862387 ,\n",
       "        0.5086188 , 0.47676012, 0.47247878, 0.43988025, 0.4339791 ,\n",
       "        0.48475406],\n",
       "       [0.49183407, 0.48405707, 0.47576582, 0.50832343, 0.4936694 ,\n",
       "        0.47059083, 0.5046688 , 0.46709898, 0.4842829 , 0.50307846,\n",
       "        0.5274215 , 0.48195082, 0.47794783, 0.4443251 , 0.4496622 ,\n",
       "        0.48804626],\n",
       "       [0.4894071 , 0.48401457, 0.47298488, 0.5051787 , 0.49985343,\n",
       "        0.47738433, 0.5139229 , 0.47237653, 0.48962763, 0.507326  ,\n",
       "        0.5369761 , 0.48816165, 0.48021734, 0.45137706, 0.45202467,\n",
       "        0.49082574],\n",
       "       [0.48077777, 0.4736551 , 0.4637357 , 0.48814392, 0.4781285 ,\n",
       "        0.46512994, 0.4881108 , 0.45894462, 0.4775622 , 0.48807007,\n",
       "        0.5138799 , 0.4724137 , 0.46508682, 0.4370634 , 0.43251285,\n",
       "        0.47745758]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diversity regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=104, shape=(), dtype=float32, numpy=0.41421354>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.convert_to_tensor([[1.,1.], [1.,2.], [2.,2.]])\n",
    "\n",
    "r = tf.expand_dims(tf.reduce_sum(x*x, 1), -1)\n",
    "\n",
    "D = r - 2 * tf.matmul(x, x, transpose_b=True) + tf.transpose(r)\n",
    "\n",
    "Rd = tf.nn.relu(tf.sqrt(D) - 1.)\n",
    "\n",
    "tf.reduce_sum(Rd) / 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=83, shape=(3, 3), dtype=float32, numpy=\n",
       "array([[-0., -1., -2.],\n",
       "       [-1., -0., -1.],\n",
       "       [-2., -1., -0.]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.convert_to_tensor([[1.,1.], [1.,2.], [2.,2.]])\n",
    "\n",
    "r = tf.expand_dims(tf.reduce_sum(x*x, 1), -1)\n",
    "\n",
    "D = r - 2 * tf.matmul(x, x, transpose_b=True) + tf.transpose(r)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=47, shape=(3, 2), dtype=float32, numpy=\n",
       "array([[1., 1.],\n",
       "       [1., 4.],\n",
       "       [4., 4.]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x is x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make2D(t):\n",
    "    \"\"\"Make a Tensor `t` 2D, raise ValueError if impossible.\"\"\"\n",
    "    ndim = tf.rank(t).numpy()\n",
    "    if ndim == 2:\n",
    "        return t\n",
    "    elif ndim == 1:\n",
    "        return tf.expand_dims(t, 0)\n",
    "    else:\n",
    "        t = tf.squeeze(t)\n",
    "        if tf.rank(t).numpy() != 2:\n",
    "            raise ValueError(f'Tensor cant be made 2D: {t}')\n",
    "        else:\n",
    "            return t\n",
    "\n",
    "\n",
    "def distance_matrix(a, b):\n",
    "    \"\"\"Return the distance matrix between rows of `a` and `b`\n",
    "\n",
    "    They must both be squeezable or expand_dims-able to 2D,\n",
    "    and have compatible shapes (same number of columns).\n",
    "    \"\"\"\n",
    "    a_was_b = a is b\n",
    "\n",
    "    a = make2D(a)\n",
    "    rA = tf.expand_dims(tf.reduce_sum(a * a, -1), -1)\n",
    "\n",
    "    if a_was_b:\n",
    "        b, rB = a, rA\n",
    "    else:\n",
    "        b = make2D(b)\n",
    "        rB = tf.expand_dims(tf.reduce_sum(b * b, -1), -1)\n",
    "\n",
    "    D = rA - 2 * tf.matmul(a, b, transpose_b=True) + tf.transpose(rB)\n",
    "\n",
    "    return tf.sqrt(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=69, shape=(3, 2), dtype=float32, numpy=\n",
       "array([[1.       , 1.4142135],\n",
       "       [0.       , 1.       ],\n",
       "       [1.       , 0.       ]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = tf.convert_to_tensor([[1.,2.], [2.,2.]])\n",
    "\n",
    "d = distance_matrix(x, y)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=130, shape=(), dtype=float32, numpy=1.0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(tf.reduce_min(d, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=173, shape=(1, 3, 2), dtype=float32, numpy=\n",
       " array([[[1., 1.],\n",
       "         [1., 2.],\n",
       "         [2., 2.]]], dtype=float32)>,\n",
       " <tf.Tensor: id=175, shape=(2, 1, 2), dtype=float32, numpy=\n",
       " array([[[1., 2.]],\n",
       " \n",
       "        [[2., 2.]]], dtype=float32)>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0 = tf.expand_dims(x, 0)\n",
    "y1 = tf.reshape(y, [2, 1, 2])\n",
    "x0, y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=181, shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1.       , 0.       , 1.       ],\n",
       "       [1.4142135, 1.       , 0.       ]], dtype=float32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.norm(x0 - y1, ord=2, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=207, shape=(3, 2), dtype=float32, numpy=\n",
       "array([[1.       , 1.4142135],\n",
       "       [0.       , 1.       ],\n",
       "       [1.       , 0.       ]], dtype=float32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_matrix(x0, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
